{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/README.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****AIM: Quora Insincere Question Classification****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  \\\n",
       "0  00002165364db923c7e6   \n",
       "1  000032939017120e6e44   \n",
       "2  0000412ca6e4628ce2cf   \n",
       "3  000042bf85aa498cd78e   \n",
       "4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                                                       question_text  \\\n",
       "0  How did Quebec nationalists see their province as a nation in the 1960s?            \n",
       "1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2  Why does velocity affect time? Does velocity affect space geometry?                 \n",
       "3  How did Otto von Guericke used the Magdeburg hemispheres?                           \n",
       "4  Can I convert montra helicon D to a mountain bike by just changing the tyres?       \n",
       "\n",
       "   target  \n",
       "0  0       \n",
       "1  0       \n",
       "2  0       \n",
       "3  0       \n",
       "4  0       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1    80810  \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset has 80810 insincere question examples and 1225312 sincere question examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arrogant when they get just a little bit of wealth and power?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineering and BMS college of engineering? Should I wait for the COMEDK result or am I supposed to apply before the result?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitioner?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  \\\n",
       "0  0000163e3ea7c7a74cd7   \n",
       "1  00002bd4fb5d505b9161   \n",
       "2  00007756b4a147d2b0b3   \n",
       "3  000086e4b7e1c7146103   \n",
       "4  0000c4c3fbe8785a3090   \n",
       "\n",
       "                                                                                                                                                        question_text  \n",
       "0  Why do so many women become so rude and arrogant when they get just a little bit of wealth and power?                                                               \n",
       "1  When should I apply for RV college of engineering and BMS college of engineering? Should I wait for the COMEDK result or am I supposed to apply before the result?  \n",
       "2  What is it really like to be a nurse practitioner?                                                                                                                  \n",
       "3  Who are entrepreneurs?                                                                                                                                              \n",
       "4  Is education really making good people nowadays?                                                                                                                    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  \\\n",
       "0  00002165364db923c7e6   \n",
       "1  000032939017120e6e44   \n",
       "2  0000412ca6e4628ce2cf   \n",
       "3  000042bf85aa498cd78e   \n",
       "4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                                                       question_text  \\\n",
       "0  How did Quebec nationalists see their province as a nation in the 1960s?            \n",
       "1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2  Why does velocity affect time? Does velocity affect space geometry?                 \n",
       "3  How did Otto von Guericke used the Magdeburg hemispheres?                           \n",
       "4  Can I convert montra helicon D to a mountain bike by just changing the tyres?       \n",
       "\n",
       "   target  \n",
       "0  0       \n",
       "1  0       \n",
       "2  0       \n",
       "3  0       \n",
       "4  0       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sincere Question Examples\n",
    "train[train['target'] == 0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0000e91571b60c2fb487</td>\n",
       "      <td>Has the United States become the largest dictatorship in the world?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>00013ceca3f624b09f42</td>\n",
       "      <td>Which babies are more sweeter to their parents? Dark skin babies or light skin babies?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0004a7fcb2bf73076489</td>\n",
       "      <td>If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>00052793eaa287aff1e1</td>\n",
       "      <td>I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>000537213b01fd77b58a</td>\n",
       "      <td>Which races have the smallest penis?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      qid  \\\n",
       "22   0000e91571b60c2fb487   \n",
       "30   00013ceca3f624b09f42   \n",
       "110  0004a7fcb2bf73076489   \n",
       "114  00052793eaa287aff1e1   \n",
       "115  000537213b01fd77b58a   \n",
       "\n",
       "                                                                                                                                 question_text  \\\n",
       "22   Has the United States become the largest dictatorship in the world?                                                                         \n",
       "30   Which babies are more sweeter to their parents? Dark skin babies or light skin babies?                                                      \n",
       "110  If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?                                      \n",
       "114  I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?   \n",
       "115  Which races have the smallest penis?                                                                                                        \n",
       "\n",
       "     target  \n",
       "22   1       \n",
       "30   1       \n",
       "110  1       \n",
       "114  1       \n",
       "115  1       "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insincere Question examples\n",
    "train[train['target'] == 1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in question text are 0\n",
      "Number of missing values in target are 0\n"
     ]
    }
   ],
   "source": [
    "#Check for missing data\n",
    "print(\"Number of missing values in question text are \" + str(train['question_text'].isnull().sum()))\n",
    "print(\"Number of missing values in target are \" + str(train['target'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_train = train['question_text'].values\n",
    "y_train = train['target'].values\n",
    "questions_test = test['question_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Keras Tokenizer:** Vectorize the text corpus. It turns text into vectors containing integers. Each integer is the index of the token in the dictionary. The parameter num of words only keeps the n most frequent words in the dictonary. This also removes all punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=90000)\n",
    "tokenizer.fit_on_texts(questions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('how', 289929), ('did', 41715), ('quebec', 166), ('nationalists', 148), ('see', 9689)]\n"
     ]
    }
   ],
   "source": [
    "print(list(tokenizer.word_counts.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306122\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('what', 2), ('is', 3), ('a', 4), ('to', 5), ('in', 6), ('of', 7), ('i', 8), ('how', 9), ('and', 10), ('do', 11), ('are', 12), ('for', 13), ('you', 14), ('can', 15)]\n"
     ]
    }
   ],
   "source": [
    "print(list(tokenizer.word_index.items())[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(questions_train)\n",
    "X_test = tokenizer.texts_to_sequences(questions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid              00002165364db923c7e6                                                    \n",
      "question_text    How did Quebec nationalists see their province as a nation in the 1960s?\n",
      "target           0                                                                       \n",
      "Name: 0, dtype: object\n",
      "[9, 48, 6683, 7219, 158, 55, 6107, 36, 4, 1206, 6, 1, 8333]\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[0,:])\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pad Sequences: ** Used to pad sequences. Pads sequences shorter than max_len and truncates longer sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 150\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding Matrix: ** All words map to some dimensional space say 300 and that is called the embedding of that word. An embedding matrix is a list of all words and their corresponding embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at\n",
      "(300,)\n",
      "[-3.6769e-01  5.9821e-01  1.3229e-01  2.3506e-01 -4.6757e-02  3.6307e-01\n",
      "  1.4099e-01 -1.0093e-01 -1.5877e-01  2.5371e+00  1.6426e-01 -1.2201e-01\n",
      "  2.1931e-01 -5.9079e-01  1.1269e-01 -6.1433e-02 -4.1994e-01  1.4899e+00\n",
      " -3.2112e-01 -8.5470e-02 -4.1711e-02 -5.4624e-02 -6.7566e-02  1.6858e-01\n",
      "  2.9859e-01  6.1769e-01 -2.9285e-01 -2.7140e-01  2.9830e-01 -8.0828e-03\n",
      "  4.5882e-01  7.4601e-02  1.6837e-01  8.5413e-01 -4.9983e-01 -1.2393e-01\n",
      " -2.8600e-01  8.7042e-01  1.8725e-01  5.3559e-01 -3.1930e-01  4.1699e-02\n",
      " -4.4677e-01  2.0253e-01  5.4033e-01  2.4753e-01 -3.7715e-01 -4.6027e-01\n",
      " -1.7242e-01  2.5339e-01  4.1274e-01  5.5843e-01 -1.6288e-01  1.5783e-01\n",
      " -1.5163e-01  9.6857e-02  4.6102e-01 -3.4735e-01 -2.4561e-01 -1.3195e-02\n",
      "  1.4734e-01 -1.2283e-01 -1.1006e-01  1.2155e-01 -3.6222e-01 -2.1340e-01\n",
      "  4.4930e-02 -1.3221e-02 -2.2636e-01  2.7993e-01  1.2472e-03 -5.0401e-01\n",
      " -7.3358e-02  1.5364e-01  7.3376e-02  4.7427e-01  5.1482e-01 -3.8231e-01\n",
      " -8.5774e-01 -2.7755e-01  3.2111e-01  1.9491e-01 -4.4249e-02 -1.2622e-01\n",
      "  4.1194e-01 -1.5178e-01  8.2253e-02 -1.0827e-02 -1.0485e-01  2.1734e-02\n",
      " -4.3701e-01  3.1045e-01  1.0883e-01 -4.5316e-01 -1.2768e-01 -2.7760e-01\n",
      " -1.1139e-01 -1.4344e-01  2.7744e-01 -9.0819e-02  4.4911e-02 -1.4890e-01\n",
      " -4.1634e-01 -1.7551e-01  2.2135e-02  5.2001e-01  4.7983e-01 -2.2133e-01\n",
      " -2.8094e-01  1.3092e-01  1.5547e-01 -6.3833e-01  2.0613e-01  5.0648e-01\n",
      "  1.7164e-02 -5.8938e-01  4.1948e-02 -2.7061e-01  5.5236e-02 -3.3485e-01\n",
      "  1.6136e-01  1.1801e-01 -4.0701e-01 -6.4496e-01  8.9917e-02  3.0720e-02\n",
      " -3.3240e-01 -1.7111e-01 -2.4695e-01  3.7055e-01 -9.4538e-02 -8.7253e-02\n",
      " -3.8874e-01  4.8253e-02 -4.0947e-01 -3.4081e-01 -3.7611e-02  6.5441e-01\n",
      "  6.8480e-02 -1.0165e-01 -4.0389e-01  1.0813e-01 -2.2223e-01 -1.9691e-01\n",
      "  2.8832e-01  1.8378e-01  1.4836e-02 -2.6287e-01 -9.6261e-02  1.0219e-01\n",
      " -1.7305e-01 -4.9914e-01 -3.8240e-01  2.1818e-01 -3.6860e-01  1.6525e-01\n",
      "  4.7200e-02 -1.0292e-01 -4.1793e-02 -1.8100e-01 -5.9390e-02 -1.6045e-01\n",
      "  4.3955e-01 -2.6214e-01  2.8116e-01  9.1289e-02  1.0214e-01  2.5554e-01\n",
      " -1.9604e-01 -1.3485e-01  3.8587e-01  1.1260e-02 -1.4089e-01 -1.9077e-02\n",
      " -2.0912e-02  2.6910e-01 -1.9602e-01  2.8619e-01 -3.6270e-02 -1.6570e-01\n",
      " -1.8118e-01 -2.4443e-01  5.2283e-01  1.1715e-01 -3.0083e-03  4.3626e-01\n",
      "  3.4315e-01  6.6219e-02  9.4045e-01  2.0832e-01 -4.9127e-01  3.2641e-01\n",
      " -4.5039e-01  1.8564e-05 -4.1278e-01  3.9304e-01  4.1150e-02  5.9372e-01\n",
      " -4.8523e-01  1.3174e-01  5.5618e-01  2.5748e-01 -7.4822e-02  2.0806e-01\n",
      "  3.6527e-01 -3.4543e-01 -1.9501e-01  1.0606e-01  1.8489e-01 -2.2234e-01\n",
      "  5.7230e-02 -1.3111e-01 -1.7341e-01 -1.4089e-01  4.9382e-02 -8.2897e-02\n",
      " -1.6355e-01  2.9960e-01  1.4933e-01  3.9375e-01  2.4239e-03 -2.1348e-01\n",
      " -3.9643e-01 -3.6238e-01  3.4257e-02  2.7043e-01  1.0181e-01 -2.5313e-02\n",
      "  5.4133e-01  1.3531e-01 -2.5421e-02  4.6123e-01  9.3227e-01 -8.9559e-02\n",
      " -5.7502e-01 -1.5075e-01 -7.4333e-01 -4.3592e-02 -1.0689e-01 -4.1813e-01\n",
      "  2.2441e-01  1.8296e-01 -9.0524e-02  1.7857e-01 -1.5199e-01 -3.4919e-01\n",
      " -4.3930e-01  3.6164e-01 -1.0558e-01  4.5816e-01 -2.8466e-02 -8.8556e-02\n",
      " -2.3875e-01 -8.9064e-02  5.1101e-01  5.5619e-01  1.8272e-01  2.8141e-01\n",
      " -3.1250e-01 -6.3815e-01  4.7544e-01  5.2737e-01  1.5876e-01  4.3863e-01\n",
      " -9.1851e-02 -3.0288e-01  9.5919e-02  1.1125e-01 -1.3932e-01 -2.4902e-02\n",
      " -1.4601e-01  6.2455e-02 -1.2562e-01 -1.1869e-01 -2.8558e-01 -1.3388e-01\n",
      "  6.4001e-01 -9.3232e-02 -3.0565e-01  5.6926e-01  1.6738e-01  1.3383e-01\n",
      " -6.9476e-02 -1.8341e-01  1.4278e-01  1.4948e-01  2.7693e-01 -1.7560e-02\n",
      "  3.1911e-01  5.8484e-01 -3.0747e-01 -3.7953e-02 -1.1377e-01 -1.5200e-02\n",
      " -3.3778e-01  2.8822e-01 -1.5941e-01  2.7228e-01 -4.8367e-02  5.8643e-01]\n"
     ]
    }
   ],
   "source": [
    "file = '/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "with open(file,errors='ignore', encoding='utf8') as f:\n",
    "    firstNlines=f.readlines()[0:30]\n",
    "print(firstNlines[25].split()[0])\n",
    "print(np.array(firstNlines[25].split()[1:],dtype=np.float32).shape)\n",
    "print(np.array(firstNlines[25].split()[1:],dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath,errors = 'ignore', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                try:\n",
    "                    embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_matrix = create_embedding_matrix ('/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt',tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding Layer**: Can be used to learn embedding with the model or it can be used to load a load a pre-trained word embedding. It is defined as the first hidden layer of the network. \n",
    "\n",
    "Parameters: \n",
    "input_dim: This is the vocabulary size.\n",
    "output_dim: Dimension of the embedding vectors.\n",
    "input_length: length of the input sequences. \n",
    "\n",
    "\n",
    "Output: \n",
    "2D vector with one embedding for each word in the input sequence of words.\n",
    "\n",
    "**Bidirectional LSTM**: It duplicates the first recurrent layer in the network. The first layer takes the input sequence as is and the second takes the reversed input sequence. These LSTMS take the future context in conideration. In Keras it is used using the Bidirectional layer wrapper. This wrapper takes\n",
    "the first recurrent layer as input and the merge mode. \n",
    "\n",
    "**Return Sequences**: This will return one output for each input time step and provide a 3D array. Set to true to stack LSTM layers together.\n",
    "\n",
    "**CuDNNLSTM**: Fast LSTM implementation with CuDNN. Needs GPU. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 300)          66648600  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 128)          187392    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               99328     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 66,935,449\n",
      "Trainable params: 286,849\n",
      "Non-trainable params: 66,648,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional\n",
    "embedding_dim = 300\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=maxlen, \n",
    "                           trainable=False))\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True),\n",
    "                        input_shape=(30, 300)))\n",
    "model.add(Bidirectional(CuDNNLSTM(64)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 300)          66648600  \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 150, 128)          187392    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               99328     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 66,935,449\n",
      "Trainable params: 286,849\n",
      "Non-trainable params: 66,648,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional\n",
    "embedding_dim = 300\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=maxlen, \n",
    "                           trainable=False))\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True),\n",
    "                        input_shape=(30, 300)))\n",
    "model.add(Bidirectional(CuDNNLSTM(64)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/10\n",
      " - 374s - loss: 0.1122 - accuracy: 0.9558 - val_loss: 0.1039 - val_accuracy: 0.9585\n",
      "Epoch 2/10\n",
      " - 370s - loss: 0.0996 - accuracy: 0.9603 - val_loss: 0.1024 - val_accuracy: 0.9587\n",
      "Epoch 3/10\n",
      " - 365s - loss: 0.0929 - accuracy: 0.9629 - val_loss: 0.1007 - val_accuracy: 0.9601\n",
      "Epoch 4/10\n",
      " - 364s - loss: 0.0867 - accuracy: 0.9651 - val_loss: 0.1015 - val_accuracy: 0.9596\n",
      "Epoch 5/10\n",
      " - 363s - loss: 0.0801 - accuracy: 0.9678 - val_loss: 0.1043 - val_accuracy: 0.9589\n",
      "Epoch 6/10\n",
      " - 363s - loss: 0.0736 - accuracy: 0.9703 - val_loss: 0.1093 - val_accuracy: 0.9585\n",
      "Epoch 7/10\n",
      " - 364s - loss: 0.0671 - accuracy: 0.9728 - val_loss: 0.1150 - val_accuracy: 0.9575\n",
      "Epoch 8/10\n",
      " - 364s - loss: 0.0611 - accuracy: 0.9752 - val_loss: 0.1209 - val_accuracy: 0.9569\n",
      "Epoch 9/10\n",
      " - 362s - loss: 0.0557 - accuracy: 0.9776 - val_loss: 0.1346 - val_accuracy: 0.9572\n",
      "Epoch 10/10\n",
      " - 363s - loss: 0.0510 - accuracy: 0.9796 - val_loss: 0.1401 - val_accuracy: 0.9552\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(x_valid,y_valid))\n",
    "loss, accuracy = model.evaluate(x_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "prediction[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds  = []\n",
    "for a in prediction:\n",
    "    preds.append(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({'qid': test['qid'],'prediction': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
